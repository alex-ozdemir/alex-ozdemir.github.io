---

title:  "Unsafe in Rust: Syntactic Patterns"
date:   2016-05-05 15:46:25 -0700
categories: rust unsafe

---

{::options toc_levels="1,2" /}

# Contents
{:.no_toc}

   * I will become TOC
{:toc}

# Introduction

[Rust][rust-lang] is a new systems programming language that seems to promise
the world: all the control of C/C++ as well as all of the safety and
convenience of your favorite high-level language.
{::comment}
It attempts to fulfill these
promises using a combination of language features that make it feel like the
mix of C++ and Haskell that you never knew you wanted until now. However, Rust
is more than just a port of functional patterns to the systems world.
{:/}
At its
heart is a statically verified system of memory management - an incarnation of
the [RAII pattern][raii] baked into the type system itself. The compiler
enforces a strict system of memory ownership which allows it to automatically
and statically determine when memory should be allocated and deallocated.
The ownership system take in combination with a few other language features
render Rust a _memory safe language_, meaning that it is impossible to read
memory your program does not currently have access to.

The problem is, while the memory management system enforced in Rust allow
programmers to write a broad class of programs, it don't allow programmers to
write _all_ programs they might be interested in writing. In particular, a
number of low level data structures are [difficult or
impossible][too-many-lists] to implement within the confines of the ownership
model. It's fairly normal for high-level languages to fail to meet all the
needs of their users, and historically many languages have addressed
shortcomings like these through Foreign Function Interface (FFI); that is, they
allow code generated by other languages to be run from their language. Most
often this looks like high-level language X calling C code to handle a data
structure or interact with the system.

Rust too allows for FFI, but it isn't the best tool in the shed for
implementing a particularly detailed data structure because Rust also provides
another option - _unsafe Rust_. As is explained in the [Rustonomicon][nomicon],
unsafe Rust is perhaps best thought of as an entirely new programming language
which is a strict superset of Rust: it allows you to do all the things you can
do in Rust, as well as a few other things that are too wild for the compiler to
verify. The existence of unsafe is great because it means that essentially any
program you're interested in writing can indeed be written in (possibly unsafe)
Rust. For example, the entirety of the Rust compiler[^llvm] and _all_ of the
Rust standard library are written in Rust (with the help of some carefully
encapsulated unsafe code).

[^llvm]:
    This is a small lie, because the Rust compiler uses LLVM as its backend,
    and LLVM is written in C++. That being said, the entirety of the Rust
    compiler frontend _is_ written in Rust.

The way unsafe works is like this: you use it by declaring that you'd like to
enter the unsafe boundary by applying the `unsafe` keyword to either a function
or a block. Then, within that function or block you're able to do a [few extra
things][unsafe-def], such as derefencing raw pointers and calling unsafe
functions. That may not sound like a lot of extra power, but believe me it is -
pointers are scary things and unsafe functions include compiler intrinsics that
do crazy things like transmute data from one type to another without any
bit-level conversion.

# The Question

So in some sense, `unsafe` is part of the secret sauce of Rust - it allows
programmers to do all the wild memory-unsafe things they need to do to
implement awesome data structures, but also requires them to declare that
they're doing so, and encourages them to bundle up their unsafe code into safe
abstractions.

The thing is, sometimes it's difficult to encapsulate unsafe code inside a safe
abstraction. In fact, sometimes its even unclear what that actually means. In a
colloquial sense it means that the Rust type system (including the ownership
model) is being respected, but this is still difficult to define and even more
difficult to verify. In fact, there has lately been [a lot][tootsie] [of
discussion][tootsie-discuss] around what the formal model for unsafe should be,
without a clear consensus.

In light of the theoretical ambiguities, it's worth investigating how unsafe
code is currently being used by real-world codebases, that is: "_How_ and _why_
do Rust programs use unsafe code?"

# The Strategy

While our guiding question is somewhat nebulous, we can quickly specify to a
few starting questions:

   * How many crates use `unsafe` in some way?
   * What unsafe operations are they performing? Dereferencing raw pointers?
       Making FFI calls? Mutating global statics?
   * What fraction of rust code is unsafe? In terms of blocks? In terms of
       functions?

The thing is - while we can start by distilling our guiding question ("_How_
and _why_ do Rust programs use unsafe code?") into specific smaller questions,
there are a million ways we could do so - our list was by no means exhaustive.

Furthermore, answering questions like these isn't the easiest thing in
the world. To start with, in order to gain access to syntactic or semantic
information about a Rust program you've got to lean on the analysis done by the
compiler, requiring you to write a compiler plugin, using the compiler's [driver
system][compiler-calls]. Then you've got to sift through the compiler's data
structures in order to extract the information you're curious about. If you're
interested in more than just the AST (perhaps you want type information, so you
can tell when pointers are being dereferenced), then you'll have to wait until
after the compiler's analysis passes have completed.

So it seems like we're in for a rough time - to get to our guiding question it
seems we need to collect a potentially large set of statistics, and aggregating
any one statistic seems like a lot of work.

Fortunately, a lot of the work to collect different statistics is identical -
we compile the same crates, get the same AST, and comb through them looking for
details relevant to `unsafe`. In fact, the details we're interested in are
often the same: the unsafe blocks, unsafe functions, and unsafe operations.

So let's cut out this redundancy! Rather than running a new plugin for each
statistic, I decided to take the compiler's data structures (specifically the
HIR) and reduce it to an Unsafe Abstract Syntax Tree (or UAST). This tree
encodes the syntactic structure of how `unsafe` is declared and used in Rust
programs.  Specifically, it describes the relationships between containers
(blocks and functions) that might declare unsafe and operations that use it
(unsafe function calls, pointer dereferences, interaction with mutable statics,
and inline assembly). It also includes information about block sizes, statement
indexes, spans, and snippets.

The result is a much simpler data structure than the original AST, which still
captures a lot of the information we're interested in when analyzing unsafe
usage patterns. Furthermore, it makes that information available without having
to run the compiler.

As an extra bonus the UAST can be serialized as JSON using `rustc_serialize`,
and the result is simple and small enough that it can be processed using
command line utilities such as [`jq`][jq].

# The Process

   1. Write a compiler plugin that acts exactly like `rustc`, but also builds a
      UAST from the HIR and dumps the UAST to standard error.
   2. Get a powerful server from Amazon Web Services.
   3. Download _all_ the crates from crates.io, using `cargo clone`.
   4. Try to build them all (unfortunately needing to build dependencies along
      the way).
   5. For those that succeed, collect the UASTs, zip them, and download them.
   6. Analyze using `jq`.

# Some Results

## How Many Crates Use `unsafe`?

As to how many crates use unsafe, out of 3,638 crates analyzed, 1,048 declared at
least one function or block unsafe. Thats just about 29%, although note that
we're missing the crate which implement unsafe traits (such as `Send` or
`Sync`) without any unsafe functions or blocks. To get how often crates use
unsafe, take a look at this Cumulative Distribution Graph:

![CDF for Unsafe Declaration Counts in Crates][unsafe-decl-in-crates]

This plot shows you, for a given number of `unsafe` functions + blocks, what
percent of crates use that many or fewer. As an example, the line crosses 80%
at ~3 funcations + blocks, so 80% of crates declare 3 or fewer `unsafe`
functions and blocks (also notice that the horizontal axis is logarithmic).

## How Much `unsafe` Is There, And Where Does It Come From?
We can also ask questions about how much unsafe there is, in terms of blocks,
functions, and uses.

### Blocks and Functions: Overview

{: .borders}
| Container Type |  Total |    Safe | Unsafe | % Unsafe |
|:-------------- |  ----- |    ---- | ------ | -------- |
| Function       | 269,070 | 258,088  |  10,982 |      4.1 |
| Block          | 557,118 | 521,547  |  35,571 |      6.4 |

### Unsafe Uses by Type and Macro Origin {#use-types}

When looking into the different types of dereferences that occured I noticed
that a large number of uses occured inside code produced by macro expansions,
so I displayed the usage counts stratified by not only usage type, but also
what type of macro they originated in (if any).

{: .borders}
| Source |Deref ptr  | Call unsafe Rust function  | Call FFI  | Use `static mut`  | Use inline ASM  | All uses |
|---|---|---|---|---|---|---|
|  `derive` macro  |0 |12,058 |0 |0 |0 |12,058 |
|  External macro  |3,732 |9,843 |161 |8,841 |80 |22,657 |
|  Local macro  |801 |8,176 |2,087 |57 |0 |11,121 |
|  Not a macro  |4,496 |18,916 |13,061 |1,264 |0 |37,737 |
|  All sources  |9,029 |48,993 |15,309 |10,162 |80 |83,573 |

### Blocks by Safety and Macro Origin

I applied the same reasoning to blocks, looking at the sources of safe and
unsafe blocks.

{: .borders}
| Block Source | Unsafe  | Safe  | All |
|---|---|---|---|
|  `derive` macro  |0 |83,488 |83,488 |
|  External macro  |7,583 |189,639 |197,222 |
|  Local macro  |4,751 |45,923 |50,674 |
|  Not a macro  |23,237 |202,497 |225,734 |
|  All sources  |35,571 |521,547 |557,118 |
| Source | Unsafe  | Safe  | All |

One point of interest in this table is the blocks generated by `derive`
procedural macros. Interestingly, they're all flagged as safe, depsite the fact
that the table before showed that `derive` produces unsafe operations
sometimes. The reason for this is that the compiler tracks when unsafe blocks
are produced by compiler, so we can easily flag those as "safe" blocks in the
UAST. In reality, the UAST should really have 3  types of blocks: Safe, Unsafe,
and CompilerUnsafe.

The compiler doesn't directly track whether expressions are compiler generated
or not (at least, I haven't seen anything about this), so we can't filter out
compiler-generated unsafe operations when building the UAST. After the fact we
can sort of filter them out by removing all unsafe operations that are not in
an unsafe block, but we would still miss those that were generated inside an
already-existing user provided unsafe block.

## What Style Do Programmers Follow For Unsafe Blocks?

There's been some discussion around the correct style to use when writing
unsafe code. The compiler only requires them to wrap certain operations, but some
have argued that large unsafe blocks are better. As an example of the "large"
style, consider this (abbreviated) [excerpt][cargo-unsafe] from cargo:

```rust
fn enabled() -> bool {
    unsafe {
        let me = kernel32::GetCurrentProcess();
        let mut ret = 0;
        let r = kernel32::IsProcessInJob(me, 0 as *mut _, &mut ret);
        assert!(r != 0);
        if ret == winapi::FALSE {
            return true
        }
        let job = kernel32::CreateJobObjectW(0 as *mut _, 0 as *const _);
        assert!(!job.is_null());
        let r = kernel32::AssignProcessToJobObject(job, me);
        kernel32::CloseHandle(job);
        r != 0
    }
}
```

Notice that while there are a lot of unsafe operations (calling the functions
from `kernel32`), not everything going on here is strictly unsafe. However,
it's also true that if someone were to change this code, they should be careful
to understand everything that is going on in order to avoid violating
invariants that make calls to these unsafe functions 'safe'. Some argue that
large unsafe blocks make this obligation more apparent.

Regardless of which way is best, I was curious which style was more common, so
I looked at two metrics:

   1. _Unsafe Block Relative Size_: How much of their parent block/function do
      unsafe blocks fill (where blocks are sized by the number of
      statements/final expressions in them and all their child blocks)?
   2. _Unsafe Block Requirement_: What amount of code (in terms of
      statements/final expressions) in an unsafe block actually requires that
      unsafe block?

### Unsafe Block Style by Crate

First I did the analysis by crate. For each crate, I attempted to summarize the
unsafe style of the crate by looking at the two statistics listed above. The
results are shown as cumulative distributions:

![Unsafe Blocks Fill Parents, by Crate][unsafe-blocks-fill-in-crates]

![Unsafe Blocks Are Required, by Crate][unsafe-blocks-required-in-crates]

The first graph shows us that in ~80% of crates, blocks tend to fill less than
half of their parent (although because total block size can be hard to pin
down, 1-to-1 nesting gets marked as 50%). However, the second graph that tells
the real story. It shows that the majority of crates (~60%) tend to put unsafe
blocks around only the statements and final expressions which require them.

### Unsafe Block Style by Block

If we stop splitting the unsafe blocks up by crate, and just look at the
distribution of 'Unsafe Block Requirement' over all crates, the trend is even
more pronounced:

![Unsafe Blocks Are Required][unsafe-blocks-required]

The graph shows that 90% of unsafe blocks are 'used' by every statement or
final expression in their body, so it seems clear that small unsafe blocks are
dramatically more common than large ones.

## How Important Is FFI In `unsafe`?

If you're familiar with Rust, one of the important things you would know about
unsafe functions is that all FFI functions (which right now include C functions
and system calls) are considered unsafe. One might wonder, "Does FFI make up a
substantial portion of unsafe code?" This is somewhat answered by the [above
table][use-types], but I decided to take it one step further and look at how
many unsafe blocks/functions _only_ perform FFI, and do no other unsafe
operations.

The results were that out of 46553 unsafe contexts (blocks or functions), 
5484 contain only FFI and  14007 contain some FFI. That comes out to just under
12% doing only FFI, which, while significant, is not a dominant trend.

# How to Get Hacking

While the above statistics are sort of neat, they're really just answers to a
tiny minority of the questions we could be asking and answering. If you're
curious about some other statistics (I.E. How often to people ignore the linter
and nest unsafe blocks?), then I encourage you to take the next step. I'll even
promise it will be fairly easy - you won't have to muck around interfacing with
the compiler or waiting several hours to compile all the crates. You'll even be
able to stick to the command line if you don't want to write Rust programs.

Just follow [this link][quickstart] to a 15 minute quickstart on how to analyze
UnsafeASTs, and keep me posted on what you find out!

[rust-lang]: https://www.rust-lang.org
[raii]: https://en.wikipedia.org/wiki/Resource_Acquisition_Is_Initialization
[too-many-lists]: http://cglab.ca/~abeinges/blah/too-many-lists/book/
[nomicon]: https://doc.rust-lang.org/nightly/nomicon/
[unsafe-def]: https://doc.rust-lang.org/book/unsafe.html#unsafe-superpowers
[tootsie]: http://smallcultfollowing.com/babysteps/blog/2016/05/27/the-tootsie-pop-model-for-unsafe-code/
[tootsie-discuss]: https://internals.rust-lang.org/t/tootsie-pop-model-for-unsafe-code/3522
[compiler-calls]: http://manishearth.github.io/rust-internals-docs/rustc_driver/index.html
[jq]: https://stedolan.github.io/jq/
[cargo-unsafe]: https://github.com/rust-lang/cargo/blob/07c1d9900de40c59b898d08d64273447560ffbe3/tests/death.rs#L17

[unsafe-decl-in-crates]: /images/2016-07-07-unsafe-declarations-by-crate.png
{: .img-large .align-center }
[unsafe-blocks-fill-in-crates]: /images/2016-07-08-unsafe-blocks-fill-crate.png
{: .img-small .align-center }
[unsafe-blocks-required-in-crates]: /images/2016-07-08-unsafe-blocks-required-fraction-crate.png
{: .img-small .align-center }
[unsafe-blocks-required]: /images/2016-07-08-unsafe-blocks-required-fraction.png
{: .img-small .align-center }
[quickstart]: https://github.com/alex-ozdemir/unsafe-ast#quickstart
